{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a59689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segmentation_models_pytorch import FPN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from pathlib import PosixPath,PurePosixPath,Path,PurePath\n",
    "import batch_norm_methods as bn_adapt\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn.parallel import DataParallel\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nrrd  \n",
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import SimpleITK as sitk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d985e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir=Path('../data/UCSF_ComeBACK/xnat.radiology.ucsf.edu/San_Francisco_cohort/')  # SF CMBK-0101\n",
    "root_dir=Path('../data/UCSF_ComeBACK/xnat.radiology.ucsf.edu/Other_sites') # Other site CMBK-0102, CMBK-0103, CMBK-0104\n",
    "# root_dir=Path('../data/UCSF_ComeBACK/COMEBACK_Controls/data/mri/')  # SF controls\n",
    "bsize=24\n",
    "alpha=0.2 # Lower alpha, more weight to Target Dataset statistics\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768423e",
   "metadata": {},
   "source": [
    "### For the patient cohorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd148362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/dkxhdycd15d4pt_h700hp40h0000gq/T/ipykernel_35601/3700556892.py:13: DtypeWarning: Columns (104,105,126,132) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv('/Users/tmcsween21/Documents/data/UCSF_ComeBACK/xnat.radiology.ucsf.edu/dicom_metadata_mid_third_slices.csv')\n"
     ]
    }
   ],
   "source": [
    "images = [str(fname) for fname in list(PurePath.joinpath(Path(root_dir)).glob(\"**/*.dcm\"))]\n",
    "\n",
    "slice_ids = [Path(x).stem for x in images]  # .stem gives the filename without extension\n",
    "patient_ids = [x.split('/')[8] for x in images]\n",
    "df = pd.DataFrame(data=list(zip(patient_ids, images, slice_ids)), columns=['patient_id', 'image', 'slice_id'])\n",
    "test_df = shuffle(df)\n",
    "test_df.head(3)\n",
    "\n",
    "metadata = pd.read_csv('../data/UCSF_ComeBACK/xnat.radiology.ucsf.edu/dicom_metadata_mid_third_slices.csv')\n",
    "metadata = metadata[metadata['PathToFolder'].str.contains('CMBK-0104')]\n",
    "metadata['FileName'] = metadata['FileName'].str.replace('.dcm', '')\n",
    "\n",
    "test_df = test_df[test_df['image'].str.contains('|'.join(metadata['FileName']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0311030",
   "metadata": {},
   "source": [
    "### For the Control cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0400bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get full file paths instead of just filenames\n",
    "# images = [str(fname) for fname in list(PurePath.joinpath(Path(root_dir)).glob(\"**/*.DCM\"))]\n",
    "\n",
    "# # subset images for entris that contain the string _T2w_\n",
    "# images = [x for x in images if '_T2w_' in x]\n",
    "\n",
    "# # make this into a dataframe\n",
    "# control_files = pd.DataFrame(images, columns=['image'])\n",
    "\n",
    "# # split by / and put the last part in a new column called lsice id\n",
    "# control_files['slice_id'] = control_files['image'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "# # split the slice id by _ and take the last part as the slice number and convert to int\n",
    "# control_files['slice_num'] = control_files['slice_id'].apply(lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# # plit image by / and take the 8th part as the patient id\n",
    "# control_files['patient_id'] = control_files['image'].apply(lambda x: x.split('/')[9])\n",
    "\n",
    "# # group by patient id and order the slice numbers into a list\n",
    "# control_files_grouped = control_files.groupby('patient_id')['slice_num'].apply(list).reset_index()\n",
    "\n",
    "# # for each row divide the length of the slice number by 3 and round down to the nearest whole number\n",
    "# control_files_grouped['num_slices'] = control_files_grouped['slice_num'].apply(lambda x: np.floor(len(x)/3))\n",
    "\n",
    "# # reorder the numbers in each list to be in sequential order\n",
    "# control_files_grouped['slice_num'] = control_files_grouped['slice_num'].apply(lambda x: sorted(x))\n",
    "\n",
    "# # remove the first x number of slices from the list where x is the number of slices divided by 3\n",
    "# control_files_grouped['middle_third'] = control_files_grouped.apply(lambda x: x['slice_num'][int(x['num_slices']):], axis=1)\n",
    "\n",
    "# # remove the last x number of slices from the list where x is the number of slices divided by 3\n",
    "# control_files_grouped['middle_third'] = control_files_grouped.apply(lambda x: x['middle_third'][:-int(x['num_slices'])], axis=1)\n",
    "\n",
    "# # drop the slice_num and num_slices columns\n",
    "# control_files_grouped.drop(['slice_num', 'num_slices'], axis=1, inplace=True)\n",
    "\n",
    "# # create a new row for each slice in the middle third list\n",
    "# control_files_grouped = control_files_grouped.explode('middle_third')\n",
    "\n",
    "# # merge the control_files_grouped dataframe with the control_files dataframe on the middle_third column and the patient_id column\n",
    "# control_files = pd.merge(control_files, control_files_grouped, how='inner', left_on=['patient_id', 'slice_num'], right_on=['patient_id', 'middle_third'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7270add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = control_files[['patient_id', 'image', 'slice_id']]\n",
    "# # remove .DCM from the end of the slice_id column\n",
    "# test_df['slice_id'] = test_df['slice_id'].str.replace('.DCM', '')\n",
    "# test_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd04bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of 150 images from test_df\n",
    "# test_df = test_df.sample(150, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a9880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpineSeg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpineSeg, self).__init__()\n",
    "        self.model=FPN(encoder_name='resnet34',in_channels=1,classes=14)\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94f4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(Dataset):\n",
    "    def __init__(self,dataset,data_slice, aug_type='test'):\n",
    "        #Assign dataset\n",
    "        self.dataset=dataset\n",
    "        # Data slice of overall dataset\n",
    "        self.data_slice = data_slice\n",
    "        # Size of the Data Slice\n",
    "        self.dataset_size = data_slice.shape[0]\n",
    "        # Apply transformations based on train or val set\n",
    "        self.aug_type = aug_type\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the filename of the image\n",
    "        slice_id = self.data_slice.iloc[index]['slice_id']\n",
    "        patient_id = self.data_slice.iloc[index]['patient_id']\n",
    "        img_file = self.data_slice.iloc[index]['slice_id'] + '.dcm' \n",
    "    \n",
    "        image_path = self.data_slice.iloc[index]['image']\n",
    "        # Load DICOM image\n",
    "        image_raw = self.load_dicom(image_path)\n",
    "        \n",
    "        # Apply transformations\n",
    "        transform_raw = self.apply_img_transforms(image_raw)\n",
    "        return {\"img_file\": img_file, \"transformed_raw\": transform_raw, \"slice_id\": slice_id, \"patient_id\": patient_id, \"image_path\": image_path}\n",
    "\n",
    "    def load_dicom(self, dicom_path):\n",
    "        \"\"\" Load a DICOM file, rescale it to [0-255], and return as uint8. \"\"\"\n",
    "        dicom = pydicom.dcmread(str(PurePosixPath(dicom_path)))\n",
    "\n",
    "        # Convert pixel data to numpy array\n",
    "        int16_image = dicom.pixel_array.astype(np.float32)\n",
    "\n",
    "        # Find min/max values\n",
    "        min_val = np.min(int16_image)\n",
    "        max_val = np.max(int16_image)\n",
    "\n",
    "        # Rescale to 0-255\n",
    "        if min_val != max_val:\n",
    "            scale = 255.0 / (max_val - min_val)\n",
    "            uint8_image = ((int16_image - min_val) * scale).round().astype(np.uint8)\n",
    "        else:\n",
    "            # Handle case where all pixel values are the same\n",
    "            uint8_image = np.ones_like(int16_image, dtype=np.uint8) * min_val\n",
    "\n",
    "        return uint8_image\n",
    "    \n",
    "    # Apply Image Transformations using Albumentations\n",
    "    # When you normalize the class labels of masks change.\n",
    "    def apply_img_transforms(self, img_raw):\n",
    "        if self.aug_type==\"test\":\n",
    "            test_transform = A.Compose(\n",
    "                 [A.Normalize(mean=0.181, std=0.184, always_apply=True, p=1.0),\n",
    "                 A.Resize(512, 512),\n",
    "                 ToTensorV2()])\n",
    "            transformed = test_transform(image=img_raw)\n",
    "            transformed_img = transformed['image']\n",
    "            # Tensors are to be converted to float tensors as cv2 is giving byte tensor\n",
    "            transformed_img = transformed_img.type(torch.FloatTensor)\n",
    "            return transformed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47572463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lumbar_mask(f):\n",
    "    lumbar_tensor=f\n",
    "    lumbar_tensor[lumbar_tensor==12] = 0\n",
    "    lumbar_tensor[lumbar_tensor==13] = 0\n",
    "\n",
    "    return lumbar_tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986ed83",
   "metadata": {},
   "source": [
    "### Generate the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc2d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={\"root_dir\":root_dir,\"img_dir\":\"images\"}\n",
    "test_ds = DatasetLoader(dataset,test_df, 'test')\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=bsize,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9f12f",
   "metadata": {},
   "source": [
    "### Load the original trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812be2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n"
     ]
    }
   ],
   "source": [
    "# load the original trained models:\n",
    "checkpoint_path=\"../data/segmentation_model_weights_14032024\"  \n",
    "\n",
    "checkpoints = list(Path(checkpoint_path).glob(\"SpineSeg*\"))\n",
    "models=[]\n",
    "for checkpoint in checkpoints:\n",
    "    model_checkpoint = checkpoint\n",
    "    model= SpineSeg()\n",
    "    state = torch.load(model_checkpoint, map_location=torch.device('cpu') )['model_state']\n",
    "    model.load_state_dict(state)\n",
    "    bn_adapt.adapt_weightedBN(model,alpha=alpha)\n",
    "    model.to(device)\n",
    "    if device == 'cuda':\n",
    "        model = DataParallel(model)\n",
    "    model.train()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9a377",
   "metadata": {},
   "source": [
    "### Run the domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "799c7012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:52, 52.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:44, 51.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:40, 53.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:37, 55.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:35, 56.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:26, 54.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [06:18, 53.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [07:07, 52.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [07:56, 51.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [08:44, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [09:32, 49.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [10:20, 49.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [11:13, 50.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [12:03, 50.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [12:54, 50.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [13:41, 49.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [14:26, 48.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [15:15, 48.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [16:01, 47.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [16:48, 47.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [17:34, 47.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [18:19, 46.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [19:11, 47.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [20:02, 49.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [20:55, 50.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [21:43, 49.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [22:28, 48.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [23:15, 47.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [23:59, 49.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Domain Adaptation Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))\n",
    "#BN Adapt\n",
    "for i,test_data in tqdm(enumerate(test_loader)):\n",
    "    print(i)\n",
    "\n",
    "    if i == 29:\n",
    "        break\n",
    "    test_images=test_data['transformed_raw'].to(device)\n",
    "    for model in models:\n",
    "        _ = model(test_images)\n",
    "print('Domain Adaptation Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020309df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9999.92684734282789915878910181250787153122-5-13-7ulnc1.dcm', '9999.31699787059162127861485996968769613189-5-14-19rvrpa.dcm', '9999.148422095646504608214593584451361252229-5-12-4fukxd.dcm', '9999.53615604897189716474771048794532318298-5-9-1d6zsqq.dcm', '9999.200329822020012919450143079036443272282-5-15-1a3i0yy.dcm', '9999.158883181974054731955445435652959704831-4-12-1q3k1tf.dcm', '9999.109740486636312245581545813160398581463-5-16-dlaxd4.dcm', '9999.199228736767843594664666847966965742768-5-17-92h4yp.dcm', 'Anon-6510483331405995986.dcm', '9999.275724190541001283042949349443038646921-5-16-sql1gg.dcm', '9999.148422095646504608214593584451361252229-5-16-21kqs9.dcm', '9999.217169010983060717519489818559071473823-5-16-2qzyen.dcm', '9999.112717985666400007954654845309037232460-5-19-1axaroi.dcm', '9999.200329822020012919450143079036443272282-5-17-56lwow.dcm', '9999.145046372870071345392296811313495476221-5-9-10l9mgk.dcm', '9999.148561699873986463543854905843721193269-5-17-1sb25i3.dcm', '9999.278178635209777451097461629695638782736-4-11-1kk3yat.dcm', 'Anon-9032871354380247072.dcm', 'Anon-75977764223261983.dcm', 'Anon-1099924467766505847.dcm', '9999.62509330208414624977194200939205348151-5-17-1yg9rfb.dcm', '9999.323102235788679971910899151413898673784-5-11-el9sep.dcm', '9999.78431100313703606066948796450898742996-11-17-1nt5j8m.dcm', '9999.216071675619280935356758635546544724098-5-9-1rdjht.dcm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:23, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     test_images \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_raw\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m----> 8\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping corrupted file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdicom_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mSpineSeg.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/segmentation_models_pytorch/base/model.py:29\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m---> 29\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m     32\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/segmentation_models_pytorch/encoders/resnet.py:62\u001b[0m, in \u001b[0;36mResNetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/resnet.py:93\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m---> 93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/radiospinomics/notebooks/batch_norm_methods.py:68\u001b[0m, in \u001b[0;36mWeightedBatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     running_mean \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mrunning_mean\u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mrunning_mean)\n\u001b[1;32m     71\u001b[0m     running_var \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mrunning_var) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mrunning_mean) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, test_data in tqdm(enumerate(test_loader)):\n",
    "    if i == 30:\n",
    "        continue\n",
    "    try:\n",
    "        dicom_path = test_data['img_file']  # Modify based on dataset structure\n",
    "        print(dicom_path)\n",
    "        test_images = test_data['transformed_raw'].to(device)\n",
    "\n",
    "        for model in models:\n",
    "            _ = model(test_images)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping corrupted file: {dicom_path} | Error: {e}\")\n",
    "        continue  # Skip to the next item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f65149",
   "metadata": {},
   "source": [
    "### Save the domain adapted model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/segmentation_model_weights_domain_adapted_UCSF_CMBK-0104'\n",
    "\n",
    "# save the models\n",
    "for i in range(len(models)):\n",
    "    torch.save({'model_state': model.state_dict()},  f'{folder}/SpineSeg_adapted_{i}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5144c8",
   "metadata": {},
   "source": [
    "### Load the domain adapted model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fa330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n",
      "| Found 36 modules to be replaced.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path=folder\n",
    "checkpoints = list(Path(checkpoint_path).glob(\"SpineSeg*\"))\n",
    "\n",
    "models = []\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    model = SpineSeg()  \n",
    "    bn_adapt.adapt_weightedBN(model, alpha=alpha)  \n",
    "    state = torch.load(checkpoint, map_location=device)['model_state']\n",
    "    model.load_state_dict(state) \n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b5df4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dicom_to_nrrd(dicom_path, nrrd_path):\n",
    "    # Load the DICOM file\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "\n",
    "    # Get pixel array and convert it to SimpleITK format\n",
    "    pixel_array = dicom_data.pixel_array.astype(np.float32)  # Ensure correct type\n",
    "    sitk_image = sitk.GetImageFromArray(pixel_array)\n",
    "\n",
    "    # Save the image as an NRRD file\n",
    "    sitk.WriteImage(sitk_image, nrrd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65646ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The length of the pixel data in the dataset (414368 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Counter to track number of batches processed\u001b[39;00m\n\u001b[1;32m     13\u001b[0m saved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Counter to track saved images\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_count \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m:\n\u001b[1;32m     18\u001b[0m         batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mDatasetLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     22\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_slice\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Load DICOM image\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m image_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dicom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[1;32m     27\u001b[0m transform_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_img_transforms(image_raw)\n",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m, in \u001b[0;36mDatasetLoader.load_dicom\u001b[0;34m(self, dicom_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m dicom \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(\u001b[38;5;28mstr\u001b[39m(PurePosixPath(dicom_path)))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Convert pixel data to numpy array\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m int16_image \u001b[38;5;241m=\u001b[39m \u001b[43mdicom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Find min/max values\u001b[39;00m\n\u001b[1;32m     38\u001b[0m min_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(int16_image)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/dataset.py:1887\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m \n\u001b[1;32m   1876\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 1.4\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;124;03m        :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1887\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/dataset.py:1444\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[0;34m(self, handler_name)\u001b[0m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_pixel_data_using_handler(handler_name)\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_pixel_data_without_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/dataset.py:1556\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_id \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1549\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to decode the pixel data using the following handlers: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see the list of supported Transfer Syntaxes in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(hh) \u001b[38;5;28;01mfor\u001b[39;00m hh \u001b[38;5;129;01min\u001b[39;00m available_handlers]))\n\u001b[1;32m   1555\u001b[0m )\n\u001b[0;32m-> 1556\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m last_exception\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/dataset.py:1536\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m available_handlers:\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1536\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_pixel_data_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1537\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/dataset.py:1563\u001b[0m, in \u001b[0;36mDataset._do_pixel_data_conversion\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual data conversion using the given handler.\"\"\"\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# Use the handler to get a 1D numpy array of the pixel data\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;66;03m# Will raise an exception if no pixel data element\u001b[39;00m\n\u001b[0;32m-> 1563\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pixeldata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m reshape_pixel_array(\u001b[38;5;28mself\u001b[39m, arr)\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;66;03m# Some handler/transfer syntax combinations may need to\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;66;03m#   convert the color space from YCbCr to RGB\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pydicom/pixel_data_handlers/numpy_handler.py:221\u001b[0m, in \u001b[0;36mget_pixeldata\u001b[0;34m(ds, read_only)\u001b[0m\n\u001b[1;32m    217\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe odd length pixel data is missing a trailing padding byte\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of the pixel data in the dataset (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m bytes) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the expected length (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m bytes). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset may be corrupted or there may be an issue \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the pixel data handler.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(actual_length, padded_expected_len)\n\u001b[1;32m    227\u001b[0m         )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m actual_length \u001b[38;5;241m>\u001b[39m padded_expected_len:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# PS 3.5, Section 8.1.1\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of the pixel data in the dataset (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m bytes) indicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit contains excess padding. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m bytes will be removed from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend of the data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(actual_length, actual_length \u001b[38;5;241m-\u001b[39m expected_len)\n\u001b[1;32m    235\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The length of the pixel data in the dataset (414368 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler."
     ]
    }
   ],
   "source": [
    "save_dir = \"../data/UCSF_ComeBACK/mask_evaluation/CMBK-0104_domain_adapted_alpha_02\"\n",
    "\n",
    "batch_count = 0  # Counter to track number of batches processed\n",
    "saved_count = 0  # Counter to track saved images\n",
    "\n",
    "for batch in test_loader:\n",
    "    \n",
    "    if batch_count <=32:\n",
    "        batch_count += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(batch_count)\n",
    "\n",
    "    images = batch['transformed_raw'].to(device)\n",
    "    batch_patient_ids = batch['patient_id']  # Extract patient IDs from the batch\n",
    "    batch_slice_ids = batch['slice_id']  # Extract slice IDs from the batch\n",
    "    batch_dicom_paths = batch['image_path']  # Extract DICOM paths from the batch\n",
    "\n",
    "    # Compute predictions\n",
    "    predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            predictions += model(images)\n",
    "\n",
    "    outputs = predictions / len(models)\n",
    "    outputs = outputs.argmax(axis=1)\n",
    "    outputs = lumbar_mask(outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    # Loop through images in batch\n",
    "    for i in range(len(outputs)):\n",
    "        # if saved_count >= 40:  # Stop once 40 images are saved\n",
    "        #     break\n",
    "\n",
    "        # Get correct identifiers from the batch\n",
    "        patient_id = batch_patient_ids[i]\n",
    "        slice_id = batch_slice_ids[i]\n",
    "        dicom_image = batch_dicom_paths[i]\n",
    "\n",
    "        if patient_id == 'CMBK-0104-00102':\n",
    "            continue\n",
    "        if patient_id == 'CMBK-0104-00003':\n",
    "            continue\n",
    "        if patient_id == 'CMBK-0104-00027':\n",
    "            continue\n",
    "\n",
    "        mask_save_path = os.path.join(save_dir, f\"{patient_id}_{slice_id}_segmentation.nrrd\")\n",
    "        print(saved_count, patient_id, slice_id)\n",
    "        print('##################')\n",
    "\n",
    "        # Save the mask NRRD file\n",
    "        corrected_mask = outputs[i].T  # Flip vertically & transpose\n",
    "        nrrd.write(mask_save_path, corrected_mask.astype(np.uint8))\n",
    "\n",
    "        # Save the DICOM as NRRD\n",
    "        nrrd_save_path = os.path.join(save_dir, f\"{patient_id}_{slice_id}.nrrd\")\n",
    "        convert_dicom_to_nrrd(dicom_image, nrrd_save_path)\n",
    "\n",
    "        # Save visualization\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(images[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(outputs[i], cmap='Paired')\n",
    "\n",
    "        png_save_path = os.path.join(save_dir, f\"{patient_id}_{slice_id}_eval.png\")\n",
    "        plt.savefig(png_save_path)\n",
    "        plt.close()\n",
    "\n",
    "        saved_count += 1\n",
    "\n",
    "    # if saved_count >= 40:  # Stop iterating over batches if we reach 40 images\n",
    "    #     break\n",
    "\n",
    "# Clean up memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff6664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d839c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
